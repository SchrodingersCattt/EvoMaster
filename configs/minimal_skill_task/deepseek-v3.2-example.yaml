# Minimal Skill Task - RAG 多 Agent 流程（Analyze → Plan → Search → Summarize）

# ============================================
# LLM 配置
# ============================================
llm:
  openai:
    provider: "openai"
    model: "gpt-5.2"
    api_key: "YOUR_OPENAI_API_KEY"
    base_url: "YOUR_OPENAI_BASE_URL"
    temperature: 0.7
    max_tokens: 16384
    timeout: 60
    max_retries: 3
    retry_delay: 1.0

  anthropic:
    provider: "anthropic"
    model: "claude-haiku-4-5-20251001"
    api_key: "YOUR_ANTHROPIC_API_KEY"
    base_url: "YOUR_ANTHROPIC_BASE_URL"
    temperature: 0.7
    max_tokens: 16384
    timeout: 60
    max_retries: 3
    retry_delay: 1.0

  local_sglang:
    provider: "deepseek"
    model: "deepseek-v3.2"
    api_key: "dummy"
    base_url: "http://127.0.0.1:18889/v1"
    temperature: 0.7
    max_tokens: 16384
    timeout: 300
    max_retries: 3
    retry_delay: 1.0

  default: "local_sglang"

# ============================================
# Agent 配置（四 Agent：analyze / plan / search / summarize）
# ============================================
agents:
  analyze:
    llm: "local_sglang"
    max_turns: 10
    enable_tools: true

    context:
      max_tokens: 128000
      truncation_strategy: "latest_half"
      preserve_system_messages: true
      preserve_recent_turns: 5

    system_prompt_file: "prompts/analyze_system_prompt.txt"
    user_prompt_file: "prompts/analyze_user_prompt.txt"

  plan:
    llm: "local_sglang"
    max_turns: 10
    enable_tools: false

    context:
      max_tokens: 128000
      truncation_strategy: "latest_half"
      preserve_system_messages: true
      preserve_recent_turns: 5

    system_prompt_file: "prompts/plan_system_prompt.txt"
    user_prompt_file: "prompts/plan_user_prompt.txt"

  search:
    llm: "local_sglang"
    max_turns: 30
    enable_tools: true

    context:
      max_tokens: 128000
      truncation_strategy: "latest_half"
      preserve_system_messages: true
      preserve_recent_turns: 5

    system_prompt_file: "prompts/search_system_prompt.txt"
    user_prompt_file: "prompts/search_user_prompt.txt"

  summarize:
    llm: "local_sglang"
    max_turns: 20
    enable_tools: true

    context:
      max_tokens: 128000
      truncation_strategy: "latest_half"
      preserve_system_messages: true
      preserve_recent_turns: 5

    system_prompt_file: "prompts/summarize_system_prompt.txt"
    user_prompt_file: "prompts/summarize_user_prompt.txt"

# ============================================
# Skills 配置（RAG 必须启用）
# ============================================
skills:
  enabled: true
  skills_root: "./evomaster/skills"

# ============================================
# MCP 配置
# ============================================
mcp:
  config_file: "mcp_config.json"
  enabled: false

# ============================================
# Session 配置
# ============================================
session:
  type: "local"

  local:
    working_dir: "./playground/minimal_skill_task/workspace"
    timeout: 300
    symlinks: {}

  docker:
    image: "evomaster/base:latest"
    container_name: null
    use_existing_container: null
    working_dir: "/workspace"
    memory_limit: "64g"
    cpu_limit: 16.0
    gpu_devices: "0"
    network_mode: "host"
    volumes: {"./playground/minimal_skill_task/workspace": "/workspace"}
    env_vars: {}
    auto_remove: false
    timeout: 300

# ============================================
# Env / 日志 / 其他
# ============================================
env:
  cluster:
    debug_pool: { type: "cpu", max_concurrent: 1 }
    train_pool: { type: "cpu", max_concurrent: 1 }
  docker:
    base_image: "python:3.11-slim"
    registry: "docker.io"
    pull_policy: "if_not_present"
  scheduler:
    type: "local"
    queue_timeout: 300
    retry_failed: false
    max_retries: 1

llm_output:
  show_in_console: true
  log_to_file: true

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: null
  console: true
  log_path: "./logs/evomaster.log"

project_root: "."
workspace: "./workspace"
results_dir: "./results"
debug: false

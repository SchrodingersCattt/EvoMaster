# ============================================
# X-Master 工作流配置
# ============================================
xmaster:
  # 每个阶段并行执行的 Agent 数量（TODO: 并行执行暂未实现，当前仅支持 agent_num=1）
  agent_num: 1
  # 线程池大小（TODO: 并行执行暂未实现）
  max_workers: 1

# ============================================
# LLM 配置
# ============================================
llm:
  openai:
    provider: "openai"
    model: "gpt-5.2"
    api_key: "YOUR_OPENAI_API_KEY"
    base_url: "YOUR_OPENAI_BASE_URL"
    temperature: 0.7
    max_tokens: 16384
    timeout: 60
    max_retries: 3
    retry_delay: 1.0

  anthropic:
    provider: "anthropic"
    model: "claude-haiku-4-5-20251001"
    api_key: "YOUR_ANTHROPIC_API_KEY"
    base_url: "YOUR_ANTHROPIC_BASE_URL"
    temperature: 0.7
    max_tokens: 16384
    timeout: 60
    max_retries: 3
    retry_delay: 1.0

  # 本地 LLM 配置示例
  local_sglang:
    provider: "deepseek"
    model: "deepseek-v3.2"
    api_key: "dummy"  # 本地部署可使用占位符
    base_url: "http://192.168.2.110:18889/v1"
    temperature: 0.7
    max_tokens: 16384
    timeout: 300  
    max_retries: 3
    retry_delay: 1.0

  default: "local_sglang"

# ============================================
# agent 配置
# ============================================

agents:
  # SolverAgent
  Solver:
    llm: "local_sglang"
    max_turns: 50
    enable_tools: True  # General Agent使用工具调用

    context:
      max_tokens: 128000
      truncation_strategy: "latest_half"
      preserve_system_messages: true
      preserve_recent_turns: 5

    # 提示词配置（相对于 playground/x_master/）
    system_prompt_file: "prompts/solver_prefix.txt"
    user_prompt_file: "prompts/solver_user.txt"

  Critic:
    llm: "local_sglang"
    max_turns: 50
    enable_tools: True  # General Agent使用工具调用

    context:
      max_tokens: 128000
      truncation_strategy: "latest_half"
      preserve_system_messages: true
      preserve_recent_turns: 5

    # 提示词配置（相对于 playground/x_master/）
    system_prompt_file: "prompts/critic_prefix.txt"
    user_prompt_file: "prompts/critic_user.txt"

  Rewriter:
    llm: "local_sglang"
    max_turns: 50
    enable_tools: True  # General Agent使用工具调用

    context:
      max_tokens: 128000
      truncation_strategy: "latest_half"
      preserve_system_messages: true
      preserve_recent_turns: 5

    # 提示词配置（相对于 playground/x_master/）
    system_prompt_file: "prompts/rewrite_prefix.txt"
    user_prompt_file: "prompts/rewrite_user.txt"

  Selector:
    llm: "local_sglang"
    max_turns: 50
    enable_tools: True  # General Agent使用工具调用

    context:
      max_tokens: 128000
      truncation_strategy: "latest_half"
      preserve_system_messages: true
      preserve_recent_turns: 5

    # 提示词配置（相对于 playground/x_master/）
    system_prompt_file: "prompts/select_prefix.txt"
    user_prompt_file: "prompts/select_user.txt"

# ============================================
# MCP 配置
# ============================================
mcp:
  # MCP 配置文件路径（相对于 config_dir）
  config_file: "mcp_config.json"

  # 是否启用 MCP（可选，默认 true）
  enabled: true


# ============================================
# Session 配置
# ============================================
session:
  # Session 类型：local 或 docker
  type: "local"  # 可选值: "local" 或 "docker"

  # 本地 Session 配置
  local:
    working_dir: "./playground/x_master/workspace"
    timeout: 60

    # 软链接配置（可选）
    # 将源目录下的所有文件和文件夹软链接到工作空间的指定位置
    # 格式：{源目录路径: 工作空间内的目标路径}
    # 目标路径是相对于工作空间的相对路径
    # 示例：
    # symlinks:
    #   "/data/exp_data/demo1bench/aerial-cactus-identification/prepared/public/": "input"
    symlinks: {}

  # Docker Session 配置
  docker:
    # Docker 镜像
    image: "evomaster/base:latest"

    # 容器名称（None 自动生成）
    container_name: null

    # 使用已存在的容器（如果设置，则使用该容器而不创建新容器）
    use_existing_container: null

    # 工作目录（容器内）
    working_dir: "/workspace"

    # 资源限制
    memory_limit: "64g"  # 内存限制，如 "4g", "8g"
    cpu_limit: 16.0      # CPU 限制（核数）
    gpu_devices: "0"   # GPU 设备，可选值：
                        #   - null: 不使用 GPU
                        #   - "all": 使用所有 GPU
                        #   - "0": 使用 GPU 0
                        #   - ["0", "1"]: 使用 GPU 0 和 1

    # 网络模式
    network_mode: "host"  # bridge, host, none

    # 挂载卷（将本地目录挂载到容器）
    # 格式：{本地路径: 容器路径}
    # 示例：
    # volumes:
    #   "./workspace": "/workspace"
    volumes: {"./playground/x_master/workspace":"/workspace"}

    # 环境变量
    # 示例：
    # env_vars:
    #   PYTHONPATH: "/workspace"
    env_vars: {}

    # 容器生命周期
    auto_remove: false   # true: 容器结束后自动删除，false: 保留容器

    # 超时时间（秒）在需要长时间执行的任务中，需要适当延长超时时间。
    timeout: 300

# ============================================
# Env 配置（环境管理）
# ============================================
env:
  # 集群配置（本地模式，最小化）
  cluster:
    debug_pool:
      type: "cpu"
      max_concurrent: 1
    train_pool:
      type: "cpu"
      max_concurrent: 1

  # Docker 配置（本地模式）
  docker:
    base_image: "python:3.11-slim"
    registry: "docker.io"
    pull_policy: "if_not_present"

  # 作业调度配置
  scheduler:
    type: "local"
    queue_timeout: 300
    retry_failed: false
    max_retries: 1

# ============================================
# 系统提示词配置（全局默认，可被 agent 配置覆盖）
# ============================================
# system_prompt_file: "prompts/system_prompt.txt"

# ============================================
# LLM 输出显示配置
# ============================================
llm_output:
  # 是否在终端实时显示 LLM 输出
  show_in_console: true

  # 是否在日志文件中记录 LLM 输出
  log_to_file: true

# ============================================
# 日志配置
# ============================================
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: null
  console: true

  # 日志文件保存路径（程序运行完成后保存）
  # 如果为 null，则不保存日志文件
  # 如果设置了路径，程序运行完成后会将日志保存到该路径
  log_path:

# ============================================
# 其他配置
# ============================================
project_root: "."
workspace: "./workspace"
results_dir: "./results"
debug: false

"""MatMasterAgent: finish only when task_completed=true.

System prompt is always generated by build_mat_master_system_prompt() (tool list + today's date).
"""

from __future__ import annotations

import json
import re
import shlex
from collections import deque
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

from evomaster.agent.agent import Agent
from .execution import BatchExecutor, ExecutionTask
from evomaster.utils.types import AssistantMessage, StepRecord, ToolMessage

# How many recent tool calls to track for loop detection
_LOOP_WINDOW = 30
# How many times the same call must appear in the window to trigger loop-break
# (1 = block on the 2nd identical call — the 1st call is the only genuine one;
#  a 2nd identical call to a deterministic tool is always wasteful.)
_LOOP_THRESHOLD = 1
# Maximum number of peek_manual search/section queries per run.
# Prevents the LLM from endlessly searching the manual with different keywords.
_PEEK_MANUAL_MAX_CALLS = 12

# Tools that are EXEMPT from loop detection and fingerprint recording.
# Job-status polling is designed to be called repeatedly with the same args
# (the caller waits for the status to change); blocking it breaks the async
# calculation workflow.
_LOOP_EXEMPT_SUFFIXES = (
    "query_job_status",
    "get_job_status",
)


class MatMasterAgent(Agent):
    """Agent that only ends the run when the finish tool is called with task_completed=true.

    If the agent calls finish with task_completed=false or partial, we add the
    tool response and continue (do not set should_finish).
    """

    def __init__(self, *args, direct_max_workers: int = 4, rate_limit: float | None = None, config_dict: dict | None = None, **kwargs):
        super().__init__(*args, **kwargs)
        # Sliding window of recent tool-call fingerprints for loop detection
        self._recent_tool_fps: deque[str] = deque(maxlen=_LOOP_WINDOW)
        # Secondary window: normalised semantic fingerprints (catches near-dupes)
        self._recent_sem_fps: deque[str] = deque(maxlen=_LOOP_WINDOW)
        # Global counter for peek_manual calls (search/section/sections queries)
        self._peek_manual_call_count: int = 0
        # Concurrency config for Direct mode (BatchExecutor)
        self._direct_max_workers: int = max(1, direct_max_workers)
        self._rate_limit: float | None = rate_limit
        # Full config dict for async tool registry (prompt injection)
        self._full_config_dict: dict = config_dict or {}

    def _get_async_tool_registry(self):
        """Lazily create AsyncToolRegistry from full config dict."""
        from .async_tool_registry import AsyncToolRegistry
        return AsyncToolRegistry(self._full_config_dict)

    @staticmethod
    def _tool_fingerprint(tool_call) -> str:
        """Create a hashable fingerprint for a tool call (name + canonical args).

        Uses sorted JSON keys so that identical calls with different key
        orderings (a common LLM behaviour) produce the same fingerprint.
        """
        name = tool_call.function.name
        args_str = tool_call.function.arguments or ""
        try:
            args_obj = json.loads(args_str) if args_str else {}
            canonical = json.dumps(args_obj, sort_keys=True, ensure_ascii=False)
        except (json.JSONDecodeError, TypeError):
            canonical = args_str
        return f"{name}|{canonical}"

    @staticmethod
    def _semantic_fingerprint(tool_call) -> str:
        """Create a normalised fingerprint that treats near-duplicate calls as identical.

        For use_skill calls that run peek_manual.py, we extract the key
        arguments (--software, --search, --section, --sections) and normalise
        them so that calls with different JSON key orderings or minor flag
        differences are recognised as the same query intent.
        """
        name = tool_call.function.name
        args_str = tool_call.function.arguments or ""
        try:
            args = json.loads(args_str) if args_str else {}
        except (json.JSONDecodeError, TypeError):
            args = {}

        # Normalise use_skill calls that run peek_manual.py
        script_args = args.get("script_args", "")
        script_name = args.get("script_name", "")
        if name == "use_skill" and "peek_manual" in script_name and script_args:
            # Extract key arguments to create a normalised fingerprint
            sa = script_args.upper()
            sw = ""
            sw_m = re.search(r'--SOFTWARE\s+(\S+)', sa)
            if sw_m:
                sw = sw_m.group(1)
            search_kw = ""
            m = re.search(r'--SEARCH\s+["\']?([^"\']+?)["\']?(?:\s+--|$)', sa)
            if m:
                search_kw = m.group(1).strip()
            section = ""
            m = re.search(r'--SECTION\s+["\']?([^"\']+?)["\']?(?:\s+--|$)', sa)
            if m:
                section = m.group(1).strip()
            sections = ""
            m = re.search(r'--SECTIONS\s+["\']?([^"\']+?)["\']?(?:\s+--|$)', sa)
            if m:
                sections = m.group(1).strip()
            tree = "--TREE" in sa
            return f"peek_manual|{sw}|search={search_kw}|section={section}|sections={sections}|tree={tree}"

        # Default: canonical JSON fingerprint (same as _tool_fingerprint)
        try:
            canonical = json.dumps(args, sort_keys=True, ensure_ascii=False)
        except TypeError:
            canonical = args_str
        return f"{name}|{canonical}"

    def _is_peek_manual_call(self, tool_call) -> bool:
        """Return True if this is a use_skill call that runs peek_manual.py."""
        name = tool_call.function.name
        if name != "use_skill":
            return False
        args_str = tool_call.function.arguments or ""
        try:
            args = json.loads(args_str) if args_str else {}
        except (json.JSONDecodeError, TypeError):
            args = {}
        return "peek_manual" in args.get("script_name", "")

    @staticmethod
    def _is_loop_exempt(tool_call) -> bool:
        """Return True if this tool is exempt from loop detection.

        Job-status polling tools (e.g. mat_abacus_query_job_status,
        mat_binary_calc_query_job_status) are designed to be called
        repeatedly with identical arguments while waiting for a status
        change. Blocking them would break the async calculation workflow.
        """
        name = tool_call.function.name or ""
        return any(name.endswith(suffix) for suffix in _LOOP_EXEMPT_SUFFIXES)

    def _is_loop(self, tool_call) -> bool:
        """Return True if this exact or semantically-equivalent call appeared >= _LOOP_THRESHOLD times,
        or if the global peek_manual budget is exhausted.

        Loop-exempt tools (job status polling) always return False.
        """
        if self._is_loop_exempt(tool_call):
            return False
        # Global budget for peek_manual queries
        if self._is_peek_manual_call(tool_call) and self._peek_manual_call_count >= _PEEK_MANUAL_MAX_CALLS:
            return True
        fp = self._tool_fingerprint(tool_call)
        if self._recent_tool_fps.count(fp) >= _LOOP_THRESHOLD:
            return True
        # Also check semantic fingerprint (catches near-duplicates)
        sem_fp = self._semantic_fingerprint(tool_call)
        if self._recent_sem_fps.count(sem_fp) >= _LOOP_THRESHOLD:
            return True
        return False

    def _record_tool_call(self, tool_call) -> None:
        """Record a tool call fingerprint in the sliding window.

        Loop-exempt tools (job status polling) are NOT recorded so they
        don't pollute the window or count toward any thresholds.
        """
        if self._is_loop_exempt(tool_call):
            return
        self._recent_tool_fps.append(self._tool_fingerprint(tool_call))
        self._recent_sem_fps.append(self._semantic_fingerprint(tool_call))
        if self._is_peek_manual_call(tool_call):
            self._peek_manual_call_count += 1

    def _collect_submit_job_map(self) -> dict[str, str]:
        """Collect ``job_id -> bohr_job_id`` from previous submit tool outputs.

        We read prior ToolMessage payloads from dialog history and extract:
        {
          "job_id": "...",
          "extra_info": {"bohr_job_id": "..."}
        }
        """
        mapping: dict[str, str] = {}
        if self.current_dialog is None:
            return mapping

        for msg in self.current_dialog.messages:
            if not isinstance(msg, ToolMessage):
                continue
            name = getattr(msg, "name", "") or ""
            # Submit tools are the only reliable source for bohr_job_id.
            if "_submit_" not in name:
                continue
            content = getattr(msg, "content", "") or ""
            try:
                payload = json.loads(content)
            except (json.JSONDecodeError, TypeError):
                continue
            if not isinstance(payload, dict):
                continue
            job_id = payload.get("job_id")
            extra_info = payload.get("extra_info") or {}
            bohr_job_id = extra_info.get("bohr_job_id") if isinstance(extra_info, dict) else None
            if isinstance(job_id, str) and isinstance(bohr_job_id, str) and job_id and bohr_job_id:
                mapping[job_id] = bohr_job_id
        return mapping

    def _maybe_patch_job_manager_bohr_id(self, tool_call) -> None:
        """Auto-fill missing ``--bohr_job_id`` for job-manager run_script calls.

        This avoids fragile failures when the LLM remembers job_id but forgets
        bohr_job_id, which is required/safer for some async backends.
        """
        if (tool_call.function.name or "") != "use_skill":
            return
        args_str = tool_call.function.arguments or ""
        try:
            args = json.loads(args_str) if args_str else {}
        except (json.JSONDecodeError, TypeError):
            return
        if not isinstance(args, dict):
            return
        if args.get("skill_name") != "job-manager":
            return
        if args.get("action") != "run_script":
            return
        if args.get("script_name") != "run_resilient_job.py":
            return

        script_args = args.get("script_args")
        if not isinstance(script_args, str) or not script_args.strip():
            return
        if "--bohr_job_id" in script_args:
            return

        try:
            tokens = shlex.split(script_args)
        except ValueError:
            return

        job_id = None
        for i, tok in enumerate(tokens):
            if tok == "--job_id" and i + 1 < len(tokens):
                job_id = tokens[i + 1]
                break
        if not job_id:
            return

        bohr_map = self._collect_submit_job_map()
        bohr_job_id = bohr_map.get(job_id)
        if not bohr_job_id:
            return

        # Keep the original script_args format, append only the missing field.
        args["script_args"] = f'{script_args} --bohr_job_id "{bohr_job_id}"'
        tool_call.function.arguments = json.dumps(args, ensure_ascii=False)
        self.logger.info(
            "Auto-patched job-manager args with bohr_job_id for job_id=%s",
            job_id,
        )

    def _get_system_prompt(self) -> str:
        """Use generated system prompt (tool list + date), then append working directory, tool rules, and skills.
        Date and OS/Shell are appended last so they appear at the end of the prompt (and in log tail)."""
        from ..prompts.build_prompt import build_mat_master_system_prompt

        # Build registry from config for dynamic prompt injection
        registry = self._get_async_tool_registry()

        base, current_date, os_type, shell_type = build_mat_master_system_prompt(registry=registry)

        working_dir = self.session.config.workspace_path
        working_dir_abs = str(Path(working_dir).absolute())
        working_dir_info = f"\n\nYou must perform all operations in this working directory; do not change directory. All file operations and commands must be run under: {working_dir_abs}"
        prompt = base + working_dir_info

        # Inject tool rules (fix once, apply every run) so repeated tool errors are avoided.
        # Placeholders like {{ASYNC_SOFTWARE_LIST}} are replaced with registry values.
        _tool_rules_path = Path(__file__).resolve().parent.parent / "prompts" / "tool_rules.txt"
        if _tool_rules_path.exists():
            tool_rules = _tool_rules_path.read_text(encoding="utf-8").strip()
            tool_rules = registry.replace_placeholders(tool_rules)
            prompt += "\n\n" + tool_rules

        # Mandatory citation and output format for survey/manuscript — agent MUST follow this
        _citation_format_path = Path(__file__).resolve().parent.parent / "skills" / "_common" / "reference" / "citation_and_output_format.md"
        if _citation_format_path.exists():
            prompt += "\n\n# Citation and output format (mandatory for literature surveys and manuscripts)\n\n"
            prompt += _citation_format_path.read_text(encoding="utf-8").strip()
            prompt += "\n\nYou MUST follow the above format when writing survey reports or manuscript sections: use [n](url) for every citation, include a References section with URL for each [n], and obey General / Citation / References section / Terminology rules."

        if self.skill_registry is not None:
            skills_info = self.skill_registry.get_meta_info_context()
            if skills_info:
                prompt += f"\n{skills_info}\n"
                prompt += """
You can use the 'use_skill' tool to:
1. Get detailed information about a skill: action='get_info'
2. Get reference documentation: action='get_reference'
3. Run scripts from Operator skills: action='run_script'
"""
        # Append date and OS/Shell last so they appear in the log tail (LLM logs truncate to head+tail)
        prompt += f"\nToday's date: {current_date} (OS: {os_type}, Shell: {shell_type})"
        return prompt

    def _on_assistant_message(self, msg: AssistantMessage) -> None:
        """Optional hook after assistant message is added. Override in subclasses (e.g. streaming)."""
        pass

    def _on_tool_message(self, msg: ToolMessage) -> None:
        """Optional hook after each tool message is added. Override in subclasses (e.g. streaming)."""
        pass

    def _execute_tools_parallel(
        self,
        tool_calls: list,
        *,
        max_workers: int = 4,
    ) -> list[tuple[Any, str, dict[str, Any]]]:
        """Execute multiple tool calls concurrently via the unified BatchExecutor.

        When the LLM returns N tool calls in a single response they are
        conceptually independent, so we run them in parallel.

        Returns a list of ``(tool_call, observation, info)`` in original order.
        """
        if not tool_calls:
            return []

        # Build ExecutionTask list — each task wraps _execute_tool for one tool_call
        batch_tasks: list[ExecutionTask] = []
        for idx, tc in enumerate(tool_calls):
            batch_tasks.append(
                ExecutionTask(
                    task_id=str(idx),
                    func=self._execute_tool,
                    kwargs={"tool_call": tc},
                    meta={"tool_call_index": idx},
                )
            )

        # Use shared BatchExecutor (true concurrency for I/O-bound tool calls)
        executor = BatchExecutor(max_workers=max_workers, rate_limit=self._rate_limit)
        results = executor.execute_batch(batch_tasks)

        # Map results back to (tool_call, observation, info) triples
        ordered: list[tuple[Any, str, dict[str, Any]]] = []
        for idx, res in enumerate(results):
            tc = tool_calls[idx]
            if res.status == "success":
                ordered.append((tc, res.output, res.info))
            else:
                # On failure, surface the error message as the observation
                ordered.append((tc, res.output or res.error or "Unknown error", res.info))
        return ordered

    def _step(self) -> bool:
        """Override: for finish tool, execute it and only set should_finish when task_completed==true."""
        self._step_count += 1

        dialog_for_query = self.context_manager.prepare_for_query(self.current_dialog)
        assistant_message = self.llm.query(dialog_for_query)
        self.current_dialog.add_message(assistant_message)
        self._on_assistant_message(assistant_message)
        step_record = StepRecord(
            step_id=self._step_count,
            assistant_message=assistant_message,
        )

        if not assistant_message.tool_calls:
            if hasattr(self, "enable_tools") and not self.enable_tools:
                self.trajectory.add_step(step_record)
                self._append_trajectory_entry(dialog_for_query, step_record)
                return True
            self._handle_no_tool_call()
            self.trajectory.add_step(step_record)
            self._append_trajectory_entry(dialog_for_query, step_record)
            return False

        should_finish = False

        # Separate finish calls from regular tool calls
        finish_call = None
        regular_calls = []
        for tool_call in assistant_message.tool_calls:
            if tool_call.function.name == "finish":
                finish_call = tool_call
            else:
                regular_calls.append(tool_call)

        # Execute regular tool calls in parallel (with loop detection)
        if regular_calls:
            # Apply guardrails before loop detection/execution.
            for tc in regular_calls:
                self._maybe_patch_job_manager_bohr_id(tc)

            # Split into executable vs loop-blocked
            exec_calls = []
            loop_blocked: list[tuple[Any, str]] = []  # (tool_call, warning_msg)
            for tc in regular_calls:
                if self._is_loop(tc):
                    # Distinguish between budget exhaustion and exact-duplicate loop
                    is_budget = (
                        self._is_peek_manual_call(tc)
                        and self._peek_manual_call_count >= _PEEK_MANUAL_MAX_CALLS
                    )
                    if is_budget:
                        self.logger.warning(
                            "BUDGET EXHAUSTED: peek_manual called %d times (max %d), skipping.",
                            self._peek_manual_call_count, _PEEK_MANUAL_MAX_CALLS,
                        )
                        msg = (
                            f"⚠️ MANUAL QUERY BUDGET EXHAUSTED: You have already called peek_manual.py "
                            f"{self._peek_manual_call_count} times (limit: {_PEEK_MANUAL_MAX_CALLS}). "
                            "ALL further manual queries are BLOCKED.\n\n"
                            "ACTION REQUIRED: STOP searching the manual. You have enough information. "
                            "Use your CP2K domain knowledge to write the input file directly NOW.\n"
                            "Many CP2K subsections (XC_FUNCTIONAL/PBE, HF, SCREENING, OT, etc.) are "
                            "valid CP2K syntax but simply not indexed in our reference JSON. "
                            "Proceed with the input file you have and submit the calculation."
                        )
                    else:
                        self.logger.warning(
                            "LOOP DETECTED: tool '%s' with same args called %d+ times, skipping.",
                            tc.function.name, _LOOP_THRESHOLD,
                        )
                        msg = (
                            f"⚠️ LOOP DETECTED: You have called '{tc.function.name}' with the exact same arguments "
                            f"{_LOOP_THRESHOLD}+ times already and received the same result each time. "
                            "This call was SKIPPED to prevent an infinite loop.\n\n"
                            "ACTION REQUIRED: Do NOT call this tool again with the same arguments. Instead:\n"
                            "1. If the parameter/section you are looking for is not in the manual, it does NOT exist. "
                            "Use your domain knowledge to write the correct syntax directly.\n"
                            "2. Try a completely DIFFERENT approach or search keyword.\n"
                            "3. If you have enough information already, proceed to write the input file NOW."
                        )
                    loop_blocked.append((tc, msg))
                else:
                    exec_calls.append(tc)
                self._record_tool_call(tc)

            # Execute non-blocked calls in parallel
            results = self._execute_tools_parallel(exec_calls, max_workers=self._direct_max_workers) if exec_calls else []

            # Merge results: first the executed ones, then the loop-blocked ones (in original order)
            all_results: list[tuple[Any, str, dict[str, Any]]] = []
            exec_iter = iter(results)
            block_iter = iter(loop_blocked)
            for tc in regular_calls:
                if any(tc is btc for btc, _ in loop_blocked):
                    btc, warn_msg = next(block_iter)
                    all_results.append((btc, warn_msg, {"loop_blocked": True}))
                else:
                    all_results.append(next(exec_iter))

            for tool_call, observation, info in all_results:
                # Remind agent to do multiple retrievals for survey
                if tool_call.function.name == "mat_sn_search-papers-enhanced" and info.get("error") is None:
                    n_papers = ""
                    try:
                        obj = json.loads(observation)
                        if isinstance(obj, dict) and "data" in obj and isinstance(obj["data"], list):
                            n_papers = str(len(obj["data"]))
                    except (json.JSONDecodeError, TypeError):
                        pass
                    call_count = info.get("call_count", "?")
                    reminder = (
                        f"\n\n[Survey reminder: 本次返回 {n_papers or '?'} 篇（第 {call_count} 次检索）。"
                        "综述/调研需至少 6–15 次检索；若结果偏少或检索次数不足，请换 question/words 继续调用 mat_sn_search-papers-enhanced 或 mat_sn_web-search。]"
                    )
                    observation = observation + reminder

                # Full content for streaming (yield) and trajectory recording
                tool_message = ToolMessage(
                    content=observation,
                    tool_call_id=tool_call.id,
                    name=tool_call.function.name,
                    meta={"info": info},
                )
                self._on_tool_message(tool_message)
                step_record.tool_responses.append(tool_message)

                # For LLM dialog: truncate if too long to prevent context overflow
                # (naive mid-string split may break JSON, but LLM only needs gist)
                MAX_TOOL_OUTPUT = 30000
                if len(observation) > MAX_TOOL_OUTPUT:
                    observation_for_llm = (
                        observation[: MAX_TOOL_OUTPUT // 2]
                        + "\n\n... [output truncated due to length] ...\n\n"
                        + observation[-MAX_TOOL_OUTPUT // 2 :]
                    )
                    dialog_message = ToolMessage(
                        content=observation_for_llm,
                        tool_call_id=tool_call.id,
                        name=tool_call.function.name,
                        meta={"info": info},
                    )
                    self.current_dialog.add_message(dialog_message)
                else:
                    self.current_dialog.add_message(tool_message)

        # Handle finish tool (always last, sequential)
        if finish_call:
            self.logger.debug("Processing tool call: finish")
            try:
                finish_args = json.loads(finish_call.function.arguments)
                self.logger.info("=" * 80)
                self.logger.info("Finish Tool Arguments: task_completed=%s", finish_args.get("task_completed"))
                self.logger.info("=" * 80)
            except Exception:
                pass

            observation, info = self._execute_tool(finish_call)

            task_completed = info.get("task_completed", "false")
            if task_completed == "true":
                should_finish = True

            # Full content for streaming (yield) and trajectory recording
            tool_message = ToolMessage(
                content=observation,
                tool_call_id=finish_call.id,
                name=finish_call.function.name,
                meta={"info": info},
            )
            self._on_tool_message(tool_message)
            step_record.tool_responses.append(tool_message)

            # For LLM dialog: truncate if too long to prevent context overflow
            MAX_TOOL_OUTPUT = 30000
            if len(observation) > MAX_TOOL_OUTPUT:
                observation_for_llm = (
                    observation[: MAX_TOOL_OUTPUT // 2]
                    + "\n\n... [output truncated due to length] ...\n\n"
                    + observation[-MAX_TOOL_OUTPUT // 2 :]
                )
                dialog_message = ToolMessage(
                    content=observation_for_llm,
                    tool_call_id=finish_call.id,
                    name=finish_call.function.name,
                    meta={"info": info},
                )
                self.current_dialog.add_message(dialog_message)
            else:
                self.current_dialog.add_message(tool_message)

        self.trajectory.add_step(step_record)
        self._append_trajectory_entry(dialog_for_query, step_record)
        return should_finish
